{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2241,"status":"ok","timestamp":1671531806602,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"rUtXHqsqtSxf","outputId":"6628d723-1b81-4b6e-dafb-707a1ed1a77b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Connect the colab notebook with drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1765,"status":"ok","timestamp":1671531808359,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"60007OhOteZo"},"outputs":[],"source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from sklearn.linear_model import LogisticRegressionCV\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1671531808360,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"4ZYbb_OBthfD"},"outputs":[],"source":["dataset =  pd.read_csv(\"/content/drive/MyDrive/Customer_Churn/Cleaned_data_24_10_22.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1671531808360,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"UaI7f3M2tjss"},"outputs":[],"source":["df = dataset[['Geography', 'Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','Exited']].copy()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1671531808361,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"E1IiJrLmtlrz","outputId":"d769f292-9d5e-44bf-9108-5eca9b817b09"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-3f2e13d7-317c-4e5d-b08d-2935284dc605\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f2e13d7-317c-4e5d-b08d-2935284dc605')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f2e13d7-317c-4e5d-b08d-2935284dc605 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f2e13d7-317c-4e5d-b08d-2935284dc605');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Geography  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n","0          0       0   42       2       0.00              1          1   \n","1          2       0   41       1   83807.86              1          0   \n","2          0       0   42       8  159660.80              3          1   \n","3          0       0   39       1       0.00              2          0   \n","4          2       0   43       2  125510.82              1          1   \n","\n","   IsActiveMember  Exited  \n","0               1       1  \n","1               1       0  \n","2               0       1  \n","3               0       0  \n","4               1       0  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head(5)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1671531808361,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"Me2MndpxtoGX"},"outputs":[],"source":["X = dataset.drop(['Exited'],axis=1)\n","y = dataset['Exited']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1671531808363,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"O3ftQfRStqUJ"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X)\n","X = scaler.transform(X)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1671531808364,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"AFIMrUr2tsff"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1671531808681,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"st_AJLEituys"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161708,"status":"ok","timestamp":1671531970380,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"F0n8Jn36txIA","outputId":"82d72c9c-9812-4cd5-86f7-b0c828c60806"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","7080 fits failed out of a total of 15000.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","1590 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","1140 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n","    raise ValueError(\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","960 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","1230 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n","    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n","ValueError: penalty='none' is not supported for the liblinear solver\n","\n","--------------------------------------------------------------------------------\n","1110 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n","    raise ValueError(\n","ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n","\n","--------------------------------------------------------------------------------\n","1050 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n","    raise ValueError(\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77725549        nan 0.77725549        nan 0.77765413 0.77762746\n"," 0.77757459 0.77613978        nan        nan        nan        nan\n"," 0.77725549        nan 0.77725549        nan        nan 0.77725549\n"," 0.7762726         nan 0.77725549 0.77746791 0.77725549 0.7757411\n"," 0.77725549        nan 0.77725549        nan 0.77725549 0.77725549\n"," 0.77645827        nan 0.77725549        nan 0.77725549 0.77717576\n","        nan 0.77725549 0.77427917        nan 0.77741481 0.77725549\n"," 0.77433227 0.77770727        nan 0.77659126        nan        nan\n","        nan        nan        nan 0.77725549        nan 0.77725549\n","        nan 0.77725549        nan        nan        nan        nan\n"," 0.77725549        nan 0.77725549 0.77752118        nan 0.77768075\n","        nan 0.77720234 0.77725549 0.50059793        nan        nan\n","        nan        nan 0.77725549 0.77725549        nan 0.77754771\n"," 0.77534248 0.77725549        nan 0.77725549 0.77568787        nan\n"," 0.50059793        nan 0.77725549 0.77781364        nan        nan\n"," 0.77736205        nan        nan 0.77728205        nan        nan\n","        nan        nan 0.7759004         nan        nan        nan\n","        nan 0.777973   0.77733517        nan 0.77738831        nan\n"," 0.77526273 0.77749457        nan        nan 0.77733517        nan\n"," 0.77725549 0.77725549 0.77725549        nan        nan 0.77725549\n"," 0.77722893 0.77725549 0.77725549        nan 0.77520957 0.77635203\n","        nan        nan 0.77794644        nan 0.75172039 0.77725549\n"," 0.77725549 0.77505012 0.77526271 0.77725549        nan 0.77725549\n"," 0.77725549        nan 0.77738816        nan 0.77720234        nan\n"," 0.77744173 0.77725549 0.77725549 0.77725549 0.77691009        nan\n"," 0.77725549 0.77728209 0.77688353 0.77725549        nan        nan\n","        nan        nan 0.77725549 0.77584734 0.77725549        nan\n","        nan        nan        nan 0.77744139        nan        nan\n"," 0.77725549 0.77725549 0.77738831        nan        nan 0.77725549\n"," 0.77778703        nan        nan 0.77746829        nan 0.77725549\n"," 0.77725549        nan 0.77582074        nan 0.77725549 0.74356282\n"," 0.77725549        nan        nan        nan 0.77725549 0.77741525\n"," 0.77725549 0.77730861 0.77725549 0.77768073        nan        nan\n"," 0.77725549        nan        nan 0.50059793 0.77725549 0.50059793\n","        nan        nan        nan 0.77725549 0.77725549 0.77725549\n","        nan 0.77725549 0.77725549        nan        nan 0.77725549\n"," 0.77754788        nan        nan        nan 0.76019702        nan\n"," 0.77725549        nan        nan        nan 0.77765408 0.77725549\n"," 0.77728205        nan 0.50059793 0.77741519        nan        nan\n"," 0.77778705 0.50059793 0.77725549 0.77725549        nan        nan\n","        nan 0.77725549 0.77725549        nan 0.77725549        nan\n"," 0.77725549 0.77635247        nan        nan        nan 0.77725549\n"," 0.77738827        nan        nan 0.77629929        nan 0.77683052\n","        nan 0.77725549        nan 0.50059793 0.77528934 0.77733519\n"," 0.77725549        nan 0.77698965 0.7763525         nan 0.77749459\n"," 0.77725549        nan 0.77688356        nan        nan 0.77725549\n","        nan        nan 0.77744139 0.77736171 0.77709591        nan\n"," 0.77725549        nan 0.77725549 0.77725549        nan 0.77752145\n","        nan        nan 0.77465121 0.77143638        nan        nan\n","        nan 0.77725549        nan 0.77746797 0.77762757        nan\n","        nan 0.77733519        nan        nan        nan 0.50059793\n"," 0.77725549        nan 0.77717576 0.77725549        nan 0.77576762\n","        nan 0.77744141        nan 0.77725549 0.77725549 0.77725549\n","        nan        nan 0.77725549 0.77725549        nan 0.77778708\n","        nan 0.77728205 0.7473092  0.77725549 0.77725549 0.77757434\n","        nan 0.7761395         nan 0.77725549 0.77725549 0.77725549\n"," 0.77725549 0.77725549 0.77725549        nan        nan 0.50059793\n"," 0.77725549        nan        nan        nan 0.77725549        nan\n"," 0.77730861        nan        nan        nan 0.77637857 0.77659126\n"," 0.77725549 0.77725549        nan 0.77672411 0.77696332 0.77725549\n","        nan        nan 0.74728264 0.77768066 0.77725549 0.77515641\n","        nan 0.77709595 0.77768083 0.77725549        nan 0.77757434\n"," 0.77725549 0.77752115 0.77738831        nan 0.77725549        nan\n","        nan        nan        nan        nan        nan 0.77741476\n","        nan 0.77773376        nan        nan 0.77725549        nan\n","        nan        nan        nan 0.77725549        nan 0.77725549\n"," 0.77725549 0.77757468 0.77725549        nan        nan 0.77725549\n"," 0.50059793 0.77558165 0.77725547 0.77691018        nan        nan\n"," 0.7758739  0.50059793 0.77611307        nan        nan        nan\n","        nan 0.77587392 0.77733517        nan 0.77611313 0.77669755\n","        nan        nan 0.77717576        nan 0.7750235         nan\n","        nan 0.77736173        nan        nan        nan        nan\n"," 0.77637901        nan        nan        nan        nan        nan\n","        nan 0.77725549 0.7773885  0.77781368        nan 0.77725549\n"," 0.50059793 0.77725549        nan 0.77725549 0.77762765        nan\n","        nan 0.77725549 0.77744177        nan        nan 0.77730897\n","        nan        nan 0.77725549        nan 0.77725549        nan\n","        nan 0.77725549        nan        nan        nan 0.77725549\n"," 0.77725549 0.77725549        nan        nan        nan        nan\n","        nan 0.77757432 0.77744135        nan 0.77778703        nan\n"," 0.77725549        nan        nan 0.77717572        nan        nan\n","        nan        nan 0.77720234        nan 0.77725549 0.77725549\n"," 0.77736169        nan 0.77736164        nan 0.77725549        nan\n"," 0.77725549        nan]\n","  warnings.warn(\n"]}],"source":["from scipy.stats import loguniform\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","# define evaluation\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","# define search space\n","space = dict()\n","space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n","space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n","space['C'] = loguniform(1e-5, 100)\n","# define search\n","lr_model = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n","# execute search\n","result = lr_model.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1671531970382,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"g6XtwGEgt3xo","outputId":"b40874a5-c306-4a77-8395-a25e101f89f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score: 0.7779729990193401\n","Best Hyperparameters: {'C': 0.002589146167630413, 'penalty': 'l2', 'solver': 'newton-cg'}\n"]}],"source":["# summarize result\n","print('Best Score: %s' % result.best_score_)\n","print('Best Hyperparameters: %s' % result.best_params_)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1671531970383,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"HESPZsi_t6a6","outputId":"cb817c4e-307e-4682-e6c5-b542da2eeb95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy against training data: 0.7785\n","\n"]}],"source":["# Predict values using the training data\n","lr_cv_predict_train = lr_model.predict(X_train)\n","\n","print(\"Accuracy against training data: {0:.4f}\".format(metrics.accuracy_score(y_train, lr_cv_predict_train)))\n","print()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1671531970384,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"HeUKfslRt8xv","outputId":"4344d58e-bd94-4b75-d730-c3d5df3a3cfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy against test data: 0.7730\n","\n"]}],"source":["# Predict values using the test data\n","lr_cv_predict_test = lr_model.predict(X_test)\n","\n","print(\"Accuracy against test data: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_cv_predict_test)))\n","print()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1671531970385,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"fwTVstSjt_G6","outputId":"37efb80b-a2c2-4053-8a07-2003dbc3e2d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix\n","[[1203  358]\n"," [ 354 1222]]\n","\n"]}],"source":["print(\"Confusion Matrix\")\n","print(metrics.confusion_matrix(y_test, lr_cv_predict_test))\n","print()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1671531970386,"user":{"displayName":"Mariya Jose","userId":"05300603228995347644"},"user_tz":0},"id":"n-2RcBepuBUL","outputId":"62953ccd-5ff8-4d8c-e230-981e47b890da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77      1561\n","           1       0.77      0.78      0.77      1576\n","\n","    accuracy                           0.77      3137\n","   macro avg       0.77      0.77      0.77      3137\n","weighted avg       0.77      0.77      0.77      3137\n","\n","\n"]}],"source":["print(\"Classification Report\")\n","print(metrics.classification_report(y_test, lr_cv_predict_test))\n","print()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAEtE+cyxhW6U8vIV/rheY","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
